---
title: TypeScript
description: TypeScript SDK for content safety - guard and redact methods
---

# TypeScript SDK

The `@superagent-ai/safety-agent` package provides two core methods: `guard()` for detecting threats and `redact()` for removing sensitive data.

## Installation

```bash
npm install @superagent-ai/safety-agent
```

## Quick Start

```typescript
import { createClient } from "@superagent-ai/safety-agent";

const client = createClient();

// Guard: Detect threats
const guardResult = await client.guard({
  input: "user message to analyze"
});

// Redact: Remove PII
const redactResult = await client.redact({
  input: "My email is john@example.com",
  model: "openai/gpt-4o-mini"
});
```

---

## Guard

The `guard()` method classifies input content as `pass` or `block`. It detects prompt injections, malicious instructions, and security threats.

### Basic Usage

```typescript
const result = await client.guard({
  input: "user message to analyze"
});

if (result.classification === "block") {
  console.log("Blocked:", result.violation_types);
  console.log("Reason:", result.reasoning);
}
```

### Options

| Option | Type | Required | Default | Description |
|--------|------|----------|---------|-------------|
| `input` | `string \| Blob \| URL` | Yes | - | The input to analyze |
| `model` | `string` | No | `superagent/guard-1.7b` | Model in `provider/model` format |
| `systemPrompt` | `string` | No | - | Custom system prompt |
| `chunkSize` | `number` | No | `8000` | Characters per chunk (0 to disable) |

### Response

| Field | Type | Description |
|-------|------|-------------|
| `classification` | `"pass" \| "block"` | Whether content passed or should be blocked |
| `reasoning` | `string` | Explanation of why content was classified as pass or block |
| `violation_types` | `string[]` | Types of violations detected |
| `cwe_codes` | `string[]` | CWE codes associated with violations |
| `usage` | `TokenUsage` | Token usage information |

### Input Types

Guard supports multiple input types:

- **Plain text**: Analyzed directly
- **URLs**: Automatically fetched and analyzed
- **Blob/File**: Analyzed based on MIME type
- **PDFs**: Text extracted and analyzed per page
- **Images**: Requires vision-capable model

```typescript
// URL input
const result = await client.guard({
  input: "https://example.com/document.pdf"
});

// Image input (requires vision model)
const result = await client.guard({
  input: imageBlob,
  model: "openai/gpt-4o"
});
```

---

## Redact

The `redact()` method removes sensitive content from text using placeholders or contextual rewriting.

### Basic Usage

```typescript
const result = await client.redact({
  input: "My email is john@example.com and SSN is 123-45-6789",
  model: "openai/gpt-4o-mini"
});

console.log(result.redacted);
// "My email is <EMAIL_REDACTED> and SSN is <SSN_REDACTED>"
```

### Options

| Option | Type | Required | Default | Description |
|--------|------|----------|---------|-------------|
| `input` | `string` | Yes | - | The text to redact |
| `model` | `string` | Yes | - | Model in `provider/model` format |
| `entities` | `string[]` | No | Default PII | Entity types to redact |
| `rewrite` | `boolean` | No | `false` | Rewrite contextually instead of placeholders |

### Response

| Field | Type | Description |
|-------|------|-------------|
| `redacted` | `string` | Sanitized text with redactions |
| `findings` | `string[]` | What was redacted |
| `usage` | `TokenUsage` | Token usage information |

### Rewrite Mode

Contextually rewrites text instead of using placeholders:

```typescript
const result = await client.redact({
  input: "My email is john@example.com",
  model: "openai/gpt-4o-mini",
  rewrite: true
});

console.log(result.redacted);
// "My email is on file"
```

### Custom Entities

Specify which entity types to redact:

```typescript
const result = await client.redact({
  input: "Contact john@example.com or call 555-123-4567",
  model: "openai/gpt-4o-mini",
  entities: ["email addresses"] // Only redact emails
});
```

### Default Entities

When `entities` is not specified:
- SSNs, Driver's License, Passport Numbers
- API Keys, Secrets, Passwords
- Names, Addresses, Phone Numbers
- Emails, Credit Card Numbers

---

## Scan

The `scan()` method analyzes a repository for AI agent-targeted attacks. It clones the repository into a secure Modal sandbox and uses OpenCode to detect threats like repo poisoning, prompt injections, and malicious instructions.

### Basic Usage

```typescript
const result = await client.scan({
  repo: "https://github.com/user/repo"
});

if (result.classification === "unsafe") {
  console.log("Found issues:", result.findings);
  console.log("Summary:", result.summary);
}
```

### Options

| Option | Type | Required | Default | Description |
|--------|------|----------|---------|-------------|
| `repo` | `string` | Yes | - | Git repository URL (https:// or git@) |
| `branch` | `string` | No | Default branch | Branch, tag, or commit to checkout |
| `model` | `string` | No | `anthropic/claude-sonnet-4-5` | Model for OpenCode analysis |
| `prompt` | `string` | No | Security prompt | Custom scanning prompt |

### Response

| Field | Type | Description |
|-------|------|-------------|
| `classification` | `"safe" \| "unsafe" \| "error"` | Overall repository classification |
| `reasoning` | `string` | Summary explanation of findings |
| `findings` | `ScanFinding[]` | List of security findings |
| `summary` | `ScanSummary` | Count of findings by severity |
| `scannedFiles` | `number` | Number of files scanned |
| `usage` | `TokenUsage` | Token usage information |
| `error` | `string` | Error message if scan failed |

### Finding Structure

```typescript
interface ScanFinding {
  file: string;        // Path to the file
  line: number;        // Line number
  severity: "critical" | "high" | "medium" | "low";
  category: ScanCategory;
  description: string; // What was found
  snippet: string;     // Code snippet
  remediation: string; // How to fix
}
```

### Threat Categories

| Category | Description |
|----------|-------------|
| `repo_poisoning` | Malicious code in build scripts, hidden backdoors |
| `prompt_injection` | Hidden instructions for AI agents in comments/docs |
| `malicious_instruction` | Code comments directing AI to bypass security |
| `suspicious_dependency` | Typosquatted packages, unusual scripts |
| `data_exfiltration` | Patterns that leak secrets or environment variables |

### Environment Variables

```bash
# Required for scan()
export MODAL_TOKEN_ID=your-modal-token-id
export MODAL_TOKEN_SECRET=your-modal-token-secret
```

### Example: Scanning a Branch

```typescript
const result = await client.scan({
  repo: "https://github.com/user/repo",
  branch: "feature-branch",
  model: "openai/gpt-4o"
});

// Check severity summary
if (result.summary.critical > 0 || result.summary.high > 0) {
  console.error("Critical/high severity issues found!");
  result.findings
    .filter(f => f.severity === "critical" || f.severity === "high")
    .forEach(f => console.log(`${f.file}:${f.line} - ${f.description}`));
}
