---
title: Guard
description: Detect and block unsafe inputs, prompt injections, and malicious tool calls
---

# Guard

The `guard()` method classifies input content as `pass` or `block`. It detects prompt injections, malicious instructions, unsafe tool calls, and other security threats.

## Basic Usage

```typescript
import { createClient } from "@superagent-ai/safety-agent";

const client = createClient();

const result = await client.guard({
  input: "user message to analyze",
  model: "openai/gpt-4o-mini"
});

if (result.classification === "block") {
  console.log("Blocked:", result.violation_types);
}
```

## Options

| Option | Type | Required | Default | Description |
|--------|------|----------|---------|-------------|
| `input` | `string \| Blob \| URL` | Yes | - | The input to analyze (text, URL, or Blob) |
| `model` | `string` | Yes | - | Model in `provider/model` format (e.g., `openai/gpt-4o-mini`) |
| `systemPrompt` | `string` | No | - | Custom system prompt that replaces the default guard prompt |
| `chunkSize` | `number` | No | `8000` | Characters per chunk. Set to `0` to disable chunking |

## Response

| Field | Type | Description |
|-------|------|-------------|
| `classification` | `"pass" \| "block"` | Whether the content passed or should be blocked |
| `violation_types` | `string[]` | Types of violations detected |
| `cwe_codes` | `string[]` | CWE codes associated with violations |
| `usage` | `TokenUsage` | Token usage information |

## Input Types

Guard supports multiple input types:

- **Plain text**: Analyzed directly
- **URLs** (starting with `http://` or `https://`): Automatically fetched and analyzed
- **Blob/File**: Analyzed based on MIME type (images use vision models)
- **URL objects**: Fetched and analyzed

## Chunking

Large inputs are automatically split into chunks and processed in parallel. Uses OR logic: blocks if ANY chunk contains a violation.

```typescript
// Auto-chunking (default: 8000 chars)
const result = await client.guard({
  input: veryLongDocument,
  model: "openai/gpt-4o-mini"
});

// Custom chunk size
const result = await client.guard({
  input: veryLongDocument,
  model: "openai/gpt-4o-mini",
  chunkSize: 4000 // Smaller chunks
});

// Disable chunking
const result = await client.guard({
  input: shortText,
  model: "openai/gpt-4o-mini",
  chunkSize: 0
});
```

## URL Input

Analyze content from a URLâ€”the content is automatically fetched and processed:

```typescript
// Analyze text from a URL
const result = await client.guard({
  input: "https://example.com/document.txt",
  model: "openai/gpt-4o-mini"
});

// Analyze JSON from an API
const result = await client.guard({
  input: "https://api.example.com/data.json",
  model: "openai/gpt-4o-mini"
});

// Using a URL object
const url = new URL("https://example.com/content");
const result = await client.guard({
  input: url,
  model: "openai/gpt-4o-mini"
});
```

## PDF Support

PDFs can be analyzed by providing a URL or Blob. Text is extracted from each page and analyzed in parallel for optimal performance.

```typescript
// Analyze PDF from URL
const result = await client.guard({
  input: "https://example.com/document.pdf",
  model: "openai/gpt-4o-mini"
});

// Analyze PDF from Blob (browser)
const pdfBlob = new Blob([pdfData], { type: 'application/pdf' });
const result = await client.guard({
  input: pdfBlob,
  model: "openai/gpt-4o-mini"
});
```

**Notes:**
- Each page is analyzed in parallel for low latency
- Uses OR logic: blocks if ANY page contains a violation
- Text extraction only (no OCR for scanned PDFs)
- Works with all text-capable models

## Image Support

Images can be analyzed using vision-capable models:

```typescript
// Analyze image from URL (auto-detected by image extension or content-type)
const result = await client.guard({
  input: "https://example.com/image.png",
  model: "openai/gpt-4o"  // Must be a vision-capable model
});

// Analyze image from Blob (browser)
const imageBlob = new Blob([imageData], { type: 'image/png' });
const result = await client.guard({
  input: imageBlob,
  model: "anthropic/claude-3-5-sonnet-20241022"
});

// Analyze uploaded file (browser)
const file = document.getElementById('upload').files[0];
const result = await client.guard({
  input: file,
  model: "google/gemini-1.5-pro"
});
```

### Supported Providers for Images

| Provider | Vision Models | Notes |
|----------|---------------|-------|
| **OpenAI** | `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, `gpt-4.1` | Full image support |
| **Anthropic** | `claude-3-*`, `claude-sonnet-4-*`, `claude-opus-4-*`, `claude-haiku-4-*` | Full image support |
| **Google** | `gemini-*` | Full image support |

Other providers (Fireworks, Groq, OpenRouter, Vercel, Bedrock) currently support text-only analysis.

### Supported Image Formats

- PNG (`image/png`)
- JPEG (`image/jpeg`, `image/jpg`)
- GIF (`image/gif`)
- WebP (`image/webp`)

## Custom System Prompts

Override the default classification behavior with your own prompt:

```typescript
const result = await client.guard({
  input: "user message",
  model: "openai/gpt-4o-mini",
  systemPrompt: `You are a safety classifier. Block any requests for medical advice.
  
  Respond with JSON: { "classification": "pass" | "block", "violation_types": [], "cwe_codes": [] }`
});
```

## Token Usage

The response includes token usage information:

```typescript
const result = await client.guard({
  input: "user message to analyze",
  model: "openai/gpt-4o-mini"
});

console.log(`Used ${result.usage.totalTokens} tokens`);
console.log(`Prompt: ${result.usage.promptTokens}, Completion: ${result.usage.completionTokens}`);
```

| Field | Type | Description |
|-------|------|-------------|
| `promptTokens` | `number` | Number of tokens in the prompt/input |
| `completionTokens` | `number` | Number of tokens in the completion/output |
| `totalTokens` | `number` | Total tokens used (promptTokens + completionTokens) |

